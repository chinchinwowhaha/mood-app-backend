import express from "express";
import cors from "cors";
import dotenv from "dotenv";

dotenv.config();

const app = express();
app.use(cors());
app.use(express.json({ limit: "1mb" }));

const PORT = process.env.PORT || 3000;

// ðŸ”’ ç°¡å–®çš„é«˜é¢¨éšªå­—è©žåµæ¸¬ï¼ˆå¿ƒç†å¥åº·å¿…å‚™ï¼‰
function isHighRisk(text = "") {
  const t = text.toLowerCase();
  const keywords = [
    "æƒ³æ­»", "è‡ªæ®º", "è‡ªæ®˜", "æ´»ä¸ä¸‹åŽ»", "çµæŸç”Ÿå‘½", "ä¸æƒ³æ´»", "å‚·å®³è‡ªå·±",
    "kill myself", "suicide", "self harm"
  ];
  return keywords.some(k => t.includes(k));
}

// ðŸ¤– å‘¼å« AIï¼ˆä¹‹å¾Œç”¨ç’°å¢ƒè®Šæ•¸æŒ‡å®šï¼‰
async function callLLM({ userText, emotion, intensity }) {
  const endpoint = process.env.LLM_ENDPOINT;
  const apiKey = process.env.LLM_API_KEY;
  const model = process.env.LLM_MODEL;

  if (!endpoint || !apiKey || !model) {
    throw new Error("Missing LLM env vars");
  }

  const systemPrompt = `
ä½ æ˜¯æº«æŸ”ã€å¯é çš„æƒ…ç·’é™ªä¼´è€…ï¼ˆä¸æ˜¯å¿ƒç†å¸«ã€ä¸æ˜¯é†«ç™‚ï¼‰ã€‚
è«‹ä¾åºåšåˆ°ï¼š
1) å…±æ„Ÿä¸€å¥ï¼ˆä¸è©•åƒ¹ï¼‰
2) æ 1â€“2 å€‹æº«æŸ”çš„å¼•å°Žå¼å•é¡Œ
3) çµ¦ 1 å€‹ 30â€“90 ç§’å¯å®Œæˆçš„å¾®è¡Œå‹•
è¼¸å‡ºæ ¼å¼å¿…é ˆæ˜¯ JSONï¼š
{"reply":"...", "suggestedEmotion":"...", "suggestedIntensity":3, "microAction":"..."}
`.trim();

  const body = {
    model,
    input: [
      { role: "system", content: systemPrompt },
      {
        role: "user",
        content: `ä½¿ç”¨è€…æ–‡å­—ï¼š${userText}\næƒ…ç·’ï¼š${emotion}ï¼Œå¼·åº¦ï¼š${intensity}`
      }
    ]
  };

  const res = await fetch(endpoint, {
    method: "POST",
    headers: {
      "Authorization": `Bearer ${apiKey}`,
      "Content-Type": "application/json"
    },
    body: JSON.stringify(body)
  });

  if (!res.ok) {
    const text = await res.text();
    throw new Error(text);
  }

  const data = await res.json();

  const raw =
    data.output_text ||
    data.text ||
    JSON.stringify(data);

  let parsed;
  try {
    parsed = JSON.parse(raw.match(/\{[\s\S]*\}/)[0]);
  } catch {
    parsed = {
      reply: "æˆ‘æœ‰è½åˆ°ä½ ç¾åœ¨çš„æ„Ÿå—ï¼Œæˆ‘å€‘å¯ä»¥æ…¢æ…¢ä¸€èµ·æ•´ç†ã€‚",
      suggestedEmotion: emotion || "neutral",
      suggestedIntensity: intensity || 3,
      microAction: "å…ˆæ·±å‘¼å¸ 3 æ¬¡ï¼Œæ„Ÿå—èº«é«”èˆ‡æ¤…å­çš„æŽ¥è§¸ã€‚"
    };
  }

  return parsed;
}

// ðŸ“© App æœƒå‘¼å«é€™å€‹ API
app.post("/chat", async (req, res) => {
  try {
    const { text, emotion, intensity } = req.body || {};

    if (!text) {
      return res.status(400).json({ error: "Missing text" });
    }

    if (isHighRisk(text)) {
      return res.json({
        reply: "æˆ‘å¾ˆåœ¨æ„ä½ çš„å®‰å…¨ï¼Œå¦‚æžœä½ æ­£åœ¨æ„Ÿåˆ°å±éšªï¼Œè«‹ç«‹åˆ»è¯çµ¡èº«é‚Šçš„äººæˆ–ç•¶åœ°ç·Šæ€¥è³‡æºã€‚",
        suggestedEmotion: "crisis",
        suggestedIntensity: 5,
        microAction: "è«‹å…ˆæŠŠèº«é‚Šå¯èƒ½é€ æˆå‚·å®³çš„ç‰©å“ç§»é ï¼Œä¸¦å˜—è©¦è¯çµ¡å¯ä¿¡ä»»çš„äººã€‚"
      });
    }

    const result = await callLLM({
      userText: text,
      emotion,
      intensity
    });

    res.json(result);
  } catch (err) {
    res.status(500).json({ error: err.message });
  }
});

// ðŸ©º Render ç”¨ä¾†æ¸¬è©¦æœå‹™æ˜¯å¦æ´»è‘—
app.get("/health", (req, res) => {
  res.json({ ok: true });
});

app.l
